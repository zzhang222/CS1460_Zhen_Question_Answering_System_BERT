{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForQuestionAnswering\n",
    "from datasets import load_dataset\n",
    "from datasets import disable_caching\n",
    "disable_caching()\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# we set up some seeds so that we can reproduce results\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "import transformers\n",
    "transformers.logging.set_verbosity_error()\n",
    "\n",
    "def load_model(device):\n",
    "  tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased-distilled-squad')\n",
    "  model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "  model.to(device)\n",
    "  return model, tokenizer\n",
    "\n",
    "def get_start_end(inputs, answer):\n",
    "  m, n = len(inputs), len(answer)\n",
    "  for i in range(m - n + 1):\n",
    "    if all(inputs[i: i+n] == answer):\n",
    "      return i, i + n - 1\n",
    "  return 0, 0\n",
    "\n",
    "def preprocess(dataset, tokenizer):\n",
    "  input_ids, attention_masks, labels = [], [], []\n",
    "  for i in range(len(dataset)):\n",
    "    answer = tokenizer(dataset[i]['answers'][0]['span_text'], return_tensors = 'pt')['input_ids'].squeeze()[1:-1]\n",
    "    question = dataset[i]['questions'][0]['input_text']\n",
    "    context = dataset[i]['contexts']\n",
    "    encoding = tokenizer.encode_plus(\n",
    "      question,\n",
    "      context,\n",
    "      add_special_tokens      = True,\n",
    "      max_length              = tokenizer.model_max_length,\n",
    "      return_token_type_ids   = False,\n",
    "      return_attention_mask   = True,\n",
    "      return_tensors          = \"pt\",\n",
    "      padding                 = \"max_length\",\n",
    "      truncation              = True\n",
    "    )\n",
    "    input_id, attention_mask = encoding['input_ids'], encoding['attention_mask']\n",
    "    start, end = get_start_end(input_id.squeeze(), answer)\n",
    "    labels.append((start, end))\n",
    "    input_ids.append(input_id)\n",
    "    attention_masks.append(attention_mask)\n",
    "  return input_ids, attention_masks, labels\n",
    "\n",
    "def preprocess_and_tokenize(dataset, tokenizer, batch_size):\n",
    "  input_ids, attention_masks, labels = preprocess(dataset, tokenizer)\n",
    "  dataset = QADataset(input_ids, attention_masks, labels)\n",
    "  return DataLoader(dataset, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset(torch.utils.data.Dataset):\n",
    "\n",
    "  def __init__(self, input_ids, attention_masks, labels):\n",
    "\n",
    "    self.input_ids = input_ids\n",
    "    self.attention_masks = attention_masks\n",
    "    self.labels = labels\n",
    "\n",
    "  def __len__(self):\n",
    "\n",
    "    return len(self.input_ids)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return {\n",
    "      'input_ids': self.input_ids[index],\n",
    "      'attention_mask': self.attention_masks[index],\n",
    "      'labels': torch.tensor(self.labels[index], dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train_loop(model, num_epochs, optimizer, lr_scheduler, train_data_loader, validation_data_loader, device):\n",
    "  train_losses, val_losses = [], []\n",
    "  for epoch in range(num_epochs):\n",
    "    # put the model in training mode (important that this is done each epoch,\n",
    "    # since we put the model into eval mode during validation)\n",
    "    model.train()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} training:\")\n",
    "    progress_bar = tqdm(range(len(train_data_loader)))\n",
    "    train_loss, val_loss, num_train, num_val = 0, 0, 0, 0\n",
    "\n",
    "    for i, batch in enumerate(train_data_loader):\n",
    "      start, end = batch['labels'][:, 0], batch['labels'][:, 1]\n",
    "      res = model(batch['input_ids'].to(device).squeeze(), batch['attention_mask'].to(device).squeeze(), start_positions = start.to(device), end_positions = end.to(device))\n",
    "      loss = res.loss\n",
    "      loss.backward()\n",
    "      batch_size = len(batch['input_ids'])\n",
    "      train_loss += loss.item() * batch_size\n",
    "      num_train += batch_size\n",
    "      optimizer.step()\n",
    "      lr_scheduler.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      progress_bar.update(1)\n",
    "    train_loss /= num_train\n",
    "\n",
    "    # print the epoch's average metrics\n",
    "    print(f\"Epoch {epoch+1} average training loss={train_loss}\")\n",
    "\n",
    "    # normally, validation would be more useful when training for many epochs\n",
    "    print(\"Running validation:\")\n",
    "    for i, batch in enumerate(validation_data_loader):\n",
    "      start, end = batch['labels'][:, 0], batch['labels'][:, 1]\n",
    "      res = model(batch['input_ids'].to(device).squeeze(), batch['attention_mask'].to(device).squeeze(), start_positions = start.to(device), end_positions = end.to(device))\n",
    "      loss = res.loss\n",
    "      batch_size = len(batch['input_ids'])\n",
    "      val_loss += loss.item() * batch_size\n",
    "      num_val += batch_size\n",
    "      progress_bar.update(1)\n",
    "    val_loss /= num_val\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} average validation loss={val_loss}\")\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "  return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def evaluate_metrics(input_ids, s, e, start, end, precision, recall, f1):\n",
    "  for input_id, s1, e1, start1, end1 in zip(input_ids, s, e, start, end):\n",
    "    pred = input_id[s1: e1 + 1]\n",
    "    ref = input_id[start1: end1 + 1]\n",
    "    counter_pred = Counter(pred.detach().cpu().numpy())\n",
    "    counter_ref = Counter(ref.detach().cpu().numpy())\n",
    "    matches = 1e-8\n",
    "    for word in counter_pred:\n",
    "      matches += min(counter_pred[word], counter_ref[word])\n",
    "    pred_length = len(pred) + 1e-8\n",
    "    ref_length = len(ref) + 1e-8\n",
    "    precision.append(matches/pred_length)\n",
    "    recall.append(matches/ref_length)\n",
    "    f1.append(2/(pred_length/matches+ref_length/matches))\n",
    "\n",
    "def eval_loop(model, validation_data_loader, device):\n",
    "  progress_bar = tqdm(range(len(validation_data_loader)))\n",
    "  precision, recall, f1 = [], [], []\n",
    "  for i, batch in enumerate(validation_data_loader):\n",
    "    start, end = batch['labels'][:, 0].to(device), batch['labels'][:, 1].to(device)\n",
    "    res = model(batch['input_ids'].to(device).squeeze(), batch['attention_mask'].to(device).squeeze())\n",
    "    s, e = res.start_logits.argmax(axis = 1), res.end_logits.argmax(axis = 1)\n",
    "    evaluate_metrics(batch['input_ids'].to(device).squeeze(), s, e, start, end, precision, recall, f1)\n",
    "    progress_bar.update(1)\n",
    "  precision = np.mean(np.array(precision))\n",
    "  recall = np.mean(np.array(recall))\n",
    "  f1 = np.mean(np.array(f1))\n",
    "  return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-40f1f9282355cd35\n",
      "Found cached dataset json (/users/zzhang99/.cache/huggingface/datasets/json/default-40f1f9282355cd35/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7a84e750384605aa06e5261dcfbfa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-825013e737ca82fb\n",
      "Found cached dataset json (/users/zzhang99/.cache/huggingface/datasets/json/default-825013e737ca82fb/0.0.0/e6070c77f18f01a5ad4551a8b7edfba20b8438b7cad4d94e6ad9378022ce4aab)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4179da7951694b39b49a594c49905dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Preprocessing.\n",
      "Epoch 1 training:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12a13d698b14ef0b9acf5c3d2368738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/581 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 average training loss=1.5888607696544703\n",
      "Running validation:\n",
      "Epoch 1 average validation loss=1.4448462908084576\n",
      "Epoch 2 training:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9fce5b7b5b64290b1845f03a67da72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/581 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 average training loss=0.8521531998987115\n",
      "Running validation:\n",
      "Epoch 2 average validation loss=1.533890254598808\n",
      "Epoch 3 training:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715f672295db4721883355e8051cd90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/581 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 average training loss=0.4539193768883901\n",
      "Running validation:\n",
      "Epoch 3 average validation loss=1.6293585708302827\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2827fdfa594442e58eb78d93f42382a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECISION:  0.7673034473562863\n",
      "RECALL:  0.7529600543503637\n",
      "F1-SCORE:  0.6935632424949435\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "def main():\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  batch_size = 24\n",
    "\n",
    "  model, tokenizer = load_model(device)\n",
    "  train = load_dataset('json', data_files = 'train.json')['train']\n",
    "  validation = load_dataset('json', data_files = 'dev.json')['train']\n",
    "\n",
    "  print('Start Preprocessing.')\n",
    "  train_data_loader = preprocess_and_tokenize(train, tokenizer, batch_size)\n",
    "  validation_data_loader = preprocess_and_tokenize(validation, tokenizer, batch_size)\n",
    "\n",
    "  num_epochs = 3\n",
    "  optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-4)\n",
    "  lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=50,\n",
    "    num_training_steps=len(train_data_loader) * num_epochs\n",
    "  )\n",
    "\n",
    "  train_losses, val_losses = train_loop(model, num_epochs, optimizer, lr_scheduler, train_data_loader, validation_data_loader, device)\n",
    "  precision, recall, f1_score  = eval_loop(model, validation_data_loader, device)\n",
    "  \n",
    "  print(\"PRECISION: \", precision)\n",
    "  print(\"RECALL: \", recall)\n",
    "  print(\"F1-SCORE: \", f1_score)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
